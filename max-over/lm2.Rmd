
```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
options(width = 100) # ширина текстового вывода
options(digits = 3) # число знаков после запятой в выводе 
```



```{r Загрузка пакетов, message = F} 
library(readr) # считывание данных из текстовых файлов
library(tidyverse) # манипулирование данными 
library(ggplot2) # визуализация 
library(GGally) # построение матрицы диаграмм рассеяния 
library(ggfortify) # визуализация диагностических графиков
library(modelr) # вспомогательные функции для работы с моделями
library(broom) # преобразование результатов моделирования в табличный вид
library(readxl)
```



```{r Загрузка данных, message = F} 
random_data50 <- read_xlsx('test_dataset.xlsx', sheet='50')
random_data500 <- read_xlsx('test_dataset.xlsx', sheet='500')
random_data5000 <- read_xlsx('test_dataset.xlsx', sheet='5000')
volume_costs <- read_xlsx('test_dataset.xlsx', sheet='vol_costs')
glimpse(random_data50) # Структура данных 
summary(random_data50) # Описательная статистика + проверка пропущенных значений 
```

```{r}
m_rnd50 <- lm(y ~ x, data = random_data50) 
coef(m_rnd50) 
```
```{r}
m_rnd500 <- lm(y ~ x, data = random_data500) 
coef(m_rnd500) 
```
```{r}
m_rnd5000 <- lm(y ~ x, data = random_data5000) 
coef(m_rnd5000) 
```

```{r}
m_volume_costs <- lm(Costs ~ Volume, data = volume_costs) 
coef(m_volume_costs) 
```


## Исследование зависимостей в данных

Когда переменных немного, зависимости между каждым фактором и целевой переменной
можно искать с помощью обычных диаграмм рассеяния. Для быстрой оценки удобно
использовать **матрицу диаграмм рассеяния** (*scatterplot matrix, SPLOM*). В
базовой графике эту визуализацию можно получить с помощью функций `pairs()` или
`car::scatterplotMatrix()`.

Для визуализации с помощью `ggplot2` можно воспользоваться функцией
`GGally:ggpairs()`. В отличие от стандартной функции, `ggpairs()` позволяет
работать и с дискретными переменными.

Узнать о том, как настроить вид графика под свои нужды, можно в
[справке](http://ggobi.github.io/ggally/#ggallyggpairs).

```{r Матрица диаграмм рассеяния с помощью ggpairs}
ggpairs(m_volume_costs, columns = c("Costs", "Volume"),  
        lower = list(continuous = wrap("smooth_lm", color = 'blue'))) # добавили тренд и покрасили точки 
```
```{r Матрица диаграмм рассеяния с помощью ggpairs}
ggpairs(m_rnd500, columns = c("x", "y"),  
        lower = list(continuous = wrap("smooth_lm", color = 'blue'))) # добавили тренд и покрасили точки 
```


На главной диагонали содержатся плотности распределения соответствующих
переменных, над ней - коэффициенты корреляции Пирсона между парами переменных.
Под диагональю содержатся диаграммы рассеяния для каждой пары переменных.


Когда переменных много и надо показать только связь факторов и целевой
переменной, можно воспользоваться стандартными возможностями `ggplot()`, однако
придется изменить структуру данных. Данные надо перевести в "длинный" формат,
слив все столбцы в один. Для этого можно воспользоваться функцией
`tidyr::pivot_longer()` (см.
http://r4ds.had.co.nz/tidy-data.html#spreading-and-gathering)



## Корреляция: количественная оценка степени линейной связи

**Коэффициент корреляции Пирсона** $r$ (*The Pearson's product-moment
correlation*) позволяет количественно оценить степень выраженности (тесноту)
линейной связи между двумя непрерывными переменными:

$$ r = \frac{cov(x, y)}{S_x S_y} =
\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n S_x S_y} $$

Для вычисления коэффициента корреляции в R можно использовать встроенную функцию
`cor()`. Функция позволяет вычислять корреляцию между парой числовых переменных
(векторов), или для всех переменных в наборе данных сразу.


```{r Коэффициенты корреляции} 
# Для двух столбцов: 
cor(volume_costs$Volume, volume_costs$Costs)
#Для всех столбцов: 
options(digits = 3) # число знаков после запятой в выводе 
volume_costs %>% 
  cor() 
```

## Почему нужна визуализация?

Во встроенном наборе данных `anscombe` содержится 4 примера данных - т.н.
[квартет Энскомба](http://tinyurl.com/anscombe-quartet).

```{r Исходная структура anscombe} 
head(anscombe, 4) 
```

Для удобства, преобразуем данные в "длинный" формат: *номер примера, x, y*.
Использование функции everything() для выделения всех столбцов 
https://www.rdocumentation.org/packages/tidyselect/versions/1.0.0/topics/select_helpers
https://tidyr.tidyverse.org/reference/pivot_longer.html


```{r Преобразование структуры данных anscombe} 

anscombe_tall <- anscombe %>%
 pivot_longer(everything(),
   names_to = c(".value", "case"),
   names_pattern = "(.)(.)"
 )
head(anscombe_tall, 30)
anscombe_tall2 <- anscombe_tall
```

Рассчитаем коэффициенты корреляции:

```{r Коэффициенты корреляции для примера anscombe}
anscombe_tall %>% group_by(case) %>% summarize(r = cor(x, y))
```

Во всех 4 примерах коэффициенты корреляции равны с точностью до двух десятичных
знаков. Однако визуализация данных показывает совершенно различный характер
зависимостей:

```{r Визуализация данных anscombe} 
ggplot(data = anscombe_tall, mapping = aes(x, y)) + 
  geom_point() + 
  facet_wrap(~ case, ncol = 2, scales = 'free_x') + 
  geom_smooth(method = 'lm', se = F, color = 'red') +
  labs(title = "Примеры зависимостей с одинаковым r = 0.82")
```

**Вывод**: хотя коэффициент корреляции позволяет количественно оценить выраженность связи,
есть ограничения в его применении:

- выявляются только линейные зависимости, 
- показатель чувствителен к выбросам в данным.



На основе свойств выборочного распределения для $r$ можно проверить
статистическую гипотезу о равенстве нулю коэффициента корреляции для
совокупности:

$$ H_0: \rho_{xy} = 0 $$

$$ H_1: \rho_{xy} \ne 0 $$

В R для проверки значимости коэффициента корреляции используется функция
`cor.test()`:

```{r Проверка значимости коэффициента корреляции для случайных данных}
with(volume_costs, cor.test(Volume, Costs))
```
Для проверки гипотезы: $$H_0: \rho = 0$$ 

против альтернативной: $$H_1: \rho \ne 0$$

используется одновыборочный t-критерий.

Статистика критерия:

$$ t = \frac{r - 0}{SE(r)}$$

В сгенерированной выборке с двумя случайными независимыми переменными
вероятность получить такое же, или большее по модулю, значение коэффициента
корреляции оказалась равна 0.08%. Таким образом, есть основания отвергнуть нулевую гипотезу.
Рассчитанное по выборке значение $r$ статистически  значимо. То есть, оно
говорит о наличии связи между $x$ и $y$ в генеральной совокупности.


```{r Проверка значимости коэффициента корреляции для случайных данных}
with(random_data50, cor.test(x, y))
```

```{r Проверка значимости коэффициента корреляции для случайных данных}
with(random_data5000, cor.test(x, y))
```

Для проверки гипотезы: $$H_0: \rho = 0$$ 

против альтернативной: $$H_1: \rho \ne 0$$

используется одновыборочный t-критерий.

Статистика критерия:

$$ t = \frac{r - 0}{SE(r)}$$

```{r}

anscombe_tall_case2 <- anscombe_tall2 %>%
  filter (case == '2')
anscombe_tall_case1
```
```{r Проверка значимости коэффициента корреляции для случайных данных}
with(anscombe_tall_case2, cor.test(x, y))
```

```{r Регрессионная прямая } 
ggplot(data = volume_costs, mapping = aes(Delivery_volume, Costs)) + 
  geom_point() + 
  geom_smooth(method=lm, se=F, color='blue') + 
  labs(title = 'Регрессионная прямая для оценки затрат\nзависимости от объема перевозок')
```

```{r Модель для оценки  зависимости } 
m_volume_costs <- lm(Costs ~ Delivery_volume, data=volume_costs) 
# Выделение коэффициентов
coef_Delvol_Costs <- coef(m_volume_costs) 
coef_Delvol_Costs
m_volume_costs
```

```{r Структура объекта для lm}
names(m_volume_costs) 
```

Наиболее часто используемые функции для работы с линейной моделью приведены в таблице:

Функция             | Возвращаемое значение
--------------------|---------------------------------------------------- 
`coef()`            | Вектор коэффициентов модели 
`confint()`         | Таблица с доверительными интервалами для коэффициентов
`fitted()`          | Вектор с прогнозами по модели на обучающей выборке
`residuals()`       | Вектор с остатками модели 
`anova()`           | Таблица дисперсионного анализа для модели



### Визуализация модели

Наиболее простой способ визуализации модели линейной регрессии - с помощью функции `geom_smooth()` пакета `ggplot`, которая автоматически строит модель по данным и добавляет ее на график. Однако этот способ позволяет визуализировать только однофакторные модели. Для моделей множественной регрессии этой возможности будет недостаточно. 

Другим способом является визуализация с помощью данных подгонки модели, возвращаемых функцией `lm()`. Можно вручную извлечь эти данные с помощью функции `fitted()` и добавить их в набор данных, либо воспользоваться функцией `modelr::add_predictions()`. Столбец с прогнозом называется `pred`.

```{r Визуализация модели по исходным данным, fig.asp=0.75}
pred_Delvol_Costs <- volume_costs %>% add_predictions(m_volume_costs)
ggplot(data = pred_Delvol_Costs) +
  geom_point(aes(Delivery_volume, Costs)) +
  geom_line(aes(Delivery_volume, pred), color = 'red') +
  labs(title='Регрессионная прямая для оценки затрат\nв зависимости от объема перевозок')
pred_Delvol_Costs
```

В этом примере мы использовали для построения линии те же данные, что и в исходном наборе. Вместо этого можно создать последовательность (сетку) значений предикторов в произвольном диапазоне, получить прогноз и использовать для построения линии новые данные. Воспользуемся функцией `modelr::data_grid()`, которая возвращает набор данных с уникальными сочетаниями всех указанных переменных исходного набора данных.

```{r Визуализация модели по сетке данных}
grid_Delvol_Costs <- volume_costs %>%
  data_grid(Delivery_volume = seq_range(Delivery_volume, 10)) %>%
  add_predictions(m_volume_costs)
grid_Delvol_Costs 
ggplot(data = pred_Delvol_Costs) +
#ggplot(data = grid_Delvol_Costs) +
  geom_point(aes(Delivery_volume, Costs)) +
 #geom_point(aes(Delivery_volume, pred)) +
  geom_line(aes(Delivery_volume, pred), data = grid_Delvol_Costs , color = 'red') +
  labs(title = 'Регрессионная прямая для оценки затрат\nв зависимости от объема перевозок')
```

Также можно вместо функции `data_grid()` сгенерировать значения факторов вручную. При этом не следует задавать границы диапазона факторов, выходящие за границы исходных данных, т.к. для этих областей регрессионну прямую придется экстраполировать, а данных для проверки того, насколько адекватна эта модель в новой области, нет.

```{r Значимость коэффициентов модели для затрат, фактор - объем перевозок}
summary(m_volume_costs)
confint(m_volume_costs)
```

Для визуализации доверительных интервалов можно получить данные о них в табличном виде при помощи функций `broom::tidy()` и `broom::confint_tidy()`.

```{r Преобразование сводки по модели в табличный вид}
Delvol_mtable <- tidy(m_volume_costs)  %>%
  bind_cols(confint_tidy(m_volume_costs))
Delvol_mtable
```



```{r Визуализация интервальных оценок коэффициентов регрессии для модели  }
ggplot(data = Delvol_mtable, mapping = aes(x = term, y = estimate)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), color = 'red') +
  geom_point() +
  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +
  labs(title = 'Интервальная оценка коэффициентов для модели с Delvol',
       x = 'Коэффициент',
       y = NULL) 
```

```{r Применение модели регрессии к новому набору данных}
new_Delvol <- tibble(Delivery_volume = seq(10000, 20000, by = 2000))
new_Delvol_pred <- predict(m_volume_costs, newdata = new_Delvol)
cbind(new_Delvol, Costs = new_Delvol_pred) # склеиваем результаты в одну таблицу
```
## Интервальный прогноз

**Интервальный прогноз** - это область вокруг точечного прогноза, в которой с заданной **доверительной вероятностью** будут содержаться фактические значения (**доверительный интервал для прогноза**, или **интервал предсказания**), или условное математическое ожидание для $y$ при заданном $x$ для совокупности (**доверительный интервал для среднего**).

В R интервальный прогноз для среднего по модели линейной регрессии можно получить непосредственно с помощью `geom_smooth()`. В числовом виде - с помощью функции `predict()`.

```{r Доверительный интервал для среднего с помощью geom_smooth}
ggplot(data = pred_Delvol_Costs, mapping = aes(Delivery_volume, Costs)) +
  geom_point() +
  geom_smooth(method = 'lm', 
              color = 'red') +
    geom_smooth(method = 'lm',
              level = .8,
              color = 'red') +
  labs(title = '80% и 90% доверительные интервалы для регрессионной прямой')
```

Интервальный прогноз для отдельных наблюдений можно получить с помощью встроенной функции `predict()`. Эта функция возвращает точечный прогноз `fit` и границы доверительного интервала выбранного типа при заданной доверительной вероятности - `lwr` и `upr`.

В этом примере мы используем для прогнозирования те же самые данные (`volume_costs'). Таким же образом можно применить модель и к новому набору данных, или к сетке данных, сгенерированной функцией `data_grid()`. 

Полученный из функции `predict()` объект надо преобразовать в набор данных с помощью функции `as.data.frame()`.

```{r Интервальный прогноз для отдельных наблюдений}
# 95% доверительный интервал для среднего
ci_Delvol_Costs <- predict(m_volume_costs, 
                        newdata = volume_costs,
                        interval = 'confidence',
                        level = 0.95) %>%
  as.data.frame() %>%
  rename(lci = lwr, uci = upr)
# 95% доверительный интервал для отдельных наблюдений
pi_Delvol_Costs <- predict(m_volume_costs, 
                        newdata = volume_costs,
                        interval = 'prediction',
                        level = 0.95) %>%
  as.data.frame() %>%
  select(-fit) %>% # точечный прогноз уже есть в наборе, удаляем этот столбец
  rename(lpi = lwr, upi = upr)
# Склеиваем все в одну таблицу
pred_Delvol_Costs2 <- bind_cols(volume_costs, ci_Delvol_Costs, pi_Delvol_Costs)
```

```{r Визуализация интервального прогноза}
p_Delvol_Costs <- ggplot(data = pred_Delvol_Costs2) +
  
  geom_ribbon(aes(Delivery_volume, ymin = lpi, ymax = upi), 
              fill = 'lightskyblue', alpha = 0.5) + 
  
  geom_ribbon(aes(Delivery_volume, ymin = lci, ymax = uci), 
              fill = 'darkgray', alpha = 0.5) +
  
  geom_line(aes(Delivery_volume, fit), color = 'red') +
  geom_point(aes(Delivery_volume, Costs)) +
  labs(title = paste('Интервальный прогноз (95% интервалы)', 
                      
                     sep = '\n'),
       y = 'Оценка затрат' )
p_Delvol_Costs
```

Интерпретация доверительных интервалов следующая:

- Можно с 95% уверенностью утверждать, что регрессионная прямая совокупности находится внутри доверительного интервала для среднего (серая область на графике) 

- С 95% вероятностью фактические значения будут находиться внутри доверительного интервала для отдельных наблюдений (синяя область на графике) 

Очевидно, что ширина доверительного интервала для отдельных наблюдений существенно больше, чем для среднего. Этот интервал определяется сочетанием двух источников ошибки: ошибки определения модельных коэффициентов и необъясненной ошибкой модели:
$$ e_i = y_i - \hat{y_i} $$
Доверительный интервал для средних определяется только ошибкой оценки модельных коэффициентов по выборке.

#############

## Обнаружение выбросов

Выбросами называются нетипичные наблюдения, на которых модель дала большую ошибку, т.е. остаток $e_i$ для такого наблюдения большой. В качестве базы для сравнения можно использовать границы доверительного интервала для отдельных наблюдений. Поскольку мы сохранили данные о границах интервала в таблицу, теперь можно воспользоваться этой информацией, чтобы найти выбросы. При необходимости, величину ошибки можно вычислить с помощью функции `modelr::add_residuals()` или встроенной функции `resid()`. Также их можно вычислить как разность факта и прогноза (`fit`)

```{r Поиск нетипичных наблюдений}
outliers_Delvol_Costs <- pred_Delvol_Costs2 %>%
  filter(Costs < lpi | Costs > upi) %>%
  mutate(Error = Costs - fit)
outliers_Delvol_Costs
# Выделение выбросов на диаграмме рассеяния (предыдущий график)
p_Delvol_Costs +
  geom_point(aes(x = Delivery_volume, y = Costs),
             data = outliers_Delvol_Costs,
             color = 'red', alpha = 0.5,
             size = 5) +
  geom_text(aes(x = Delivery_volume, y = Costs),
            data = outliers_Delvol_Costs, label = "outlier", 
            vjust = -0.8 )
```

# Оценка полезности модели

Из двух моделей более полезна та, которая дает более точные прогнозы, т.е. модель с наименьшей ошибкой прогноза. Существует несколько показателей, позволяющих оценить величину ошибки прогноза. Также ошибка может вычисляться на обучающей выборке (те же данные, которые использовались при моделировании) или на тестовой выборке. В классическом анализе используются показатели ошибки на обучающей выборке. Их вычисляют встроенные функции R.

## Лучший прогноз без использования объясняющих переменных

Можно показать, что если не используется никакой дополнительной информации, то лучшим прогнозом для выходной переменной будет ее среднее значение. В нашем примере:

$$ \widehat{costs} = \overline{costs} $$

```{r Визуализация прогноза по среднему}
ggplot(data = volume_costs, mapping = aes(Delivery_volume, Costs)) +
  geom_point() +
  geom_hline(aes(yintercept = mean(Costs)), color = 'red', linetype = 'dashed') +
  geom_linerange(aes(ymin = mean(Costs), ymax = Costs))
```


Ошибки для данного прогноза - это вертикальные расстояния от точек наблюдений до линии среднего. Поскольку разброс оценок вкусовых качеств большой и ни одна из них не лежит на линии среднего значения, ошибка данного прогноза будет большой. Тем не менее, использование в качестве прогноза любого другого числа, кроме среднего, даст еще большую ошибку.

Для количественной оценки ошибки используется стандартное отклонение выходной переменной:

$$ S_y = \sqrt{ \frac{1}{N-1} \sum_{i=1}^N (y_i - \bar{y})^2 } $$


## Лучший проноз при использовании объясняющей переменной Lactic

Если включить в модель информацию о объеме перевозок то прогнозом будет линия регрессии, уровень которой пропорционален значению переменной `Delivery_volume`. Коэффициенты этой прямой найдены по критерию минимизации суммы квадратов остатков для модели. 

При использовании линейной модели остатки модели - это вертикальные расстояния от точек наблюдений до регрессионной прямой.

```{r}
pred_Delvol_Costs
pred_Delvol_Costs2

```


```{r Визуализация прогноза по регрессионной прямой}
ggplot(data = pred_Delvol_Costs, mapping = aes(Delivery_volume, Costs)) +
  geom_point() +
  geom_line(aes(y = pred), color = 'red' ) +
  #geom_line(aes(y = Costs), color = 'red' ) +
  geom_hline(aes(yintercept = mean(Costs)), color = 'red', linetype = 'dashed') +
  geom_linerange(aes(ymin = mean(Costs), ymax = Costs), 
                 color = 'darkgray', linetype = 'dashed') +
  geom_linerange(aes(ymin = pred, ymax = Costs))
```

По графику видно, что ошибки второй модели меньше. Количественной мерой ошибки этой модели является **стандартная ошибка оценки** (*residual standard error*):

$$ S_e = \sqrt{\frac{1}{N-2} \sum_{i=1}^N {e_i^2}} $$

Формула напоминает формулу для стандартного отклонения, но в ней используются отклонения не от среднего, а от прогноза, а также уменьшено число степеней свободы при усреднении. В отличие от среднего, здесь два параметра модели (коэффициенты) определялись по той же самой выборке.


Сравним стандартное отклонение и стандартную ошибку оценки численно:

```{r Сравнение ошибок нулевой модели и модели с одним фактором}
# Стандартное отклонение: 
paste('Стандартное отклонение:', round(sd(volume_costs$Costs), 1))
RSE_Delvol = summary(m_volume_costs)$'sigma'
paste('Стандартная ошибка оценки:', round(RSE_Delvol, 1))
```

Модель с объясняющей переменной имеет меньшую ошибку, поэтому она лучше чем базовая модель без предикторов (прогнозирование по среднему).

## Коэффициент детерминации $R^2$

Другим общепринятым средством оценки эффективности моделей является показатель $R^2$ - коэффициент детерминации (англ. *coefficient of determination*,  R-squared). Этот показатель характеризует, несколько хорошо линейная модель объясняет дисперсию (разброс) в исходных данных.

Показатель равен доле объясненной дисперсии исходных данных:

$$ R^2 = 1 - \frac{RSS}{TSS}, $$

где: 

$$RSS=\sum{e_i^2} = \sum{(y_i - \hat{y_i})^2}$$ -  **Остаточная сумма квадратов** 
(*Residual Sum of Squares*), вычисляемая на основе остатков регрессионной модели.
Эта сумма зависит от дисперсии целевой переменной, не объясненной моделью;


$$ TSS = \sum{(y_i - \bar{y})^2} $$ - **Полная сумма квадратов** (*Total Sum of Squares*), вычисляемая на основев остатков нуль-модели без предикторов (т.е. относительно среднего). Эта сумма зависит от дисперсии целевой переменной.


Отношение $RSS/TSS$ характеризует **долю необъясненной дисперсии** целевой переменной. 
Поэтому  $1 - RSS/TSS$ - это **доля объясненной дисперсии* целевой переменной.
![Суммы квадратов](figures/Coefficient_of_Determination.png)
Для простой линейной регрессии с одной переменной коэффициент детерминации может быть вычислен через коэффициент корреляции Пирсона:
$$ R^2 = r^2 $$
Т.к  $ |r| \le 1 $, диапазон возможных значений коэффициента детерминации для линейной модели:
$$0 \le R^2 \le 1.$$
Если объясняющая и целевая переменная некоррелированы, то модель не сможет объяснить разброс значений целевой переменной. При идеальной линейной связи оба коэффициента равны 1.
В R значение коэффициента детерминации можно извлечь из сводки по линейной модели.
```{r Получение коэффициента детерминации модели с Lactic} 
Rsq_Delvol <- summary(m_volume_costs)$r.squared 
Rsq_Delvol
with(volume_costs, cor(Delivery_volume, Costs)^2) 
```
Все статистики по модели можно получить в табличном виде с помощью функции `tidyr::glance()`.
```{r Сводка по модели в табличном виде с помощью glance}
glance(m_volume_costs)
```
## Таблица дисперсионного анализа и оценка значимости модели в целом
Таблица дисперсионного анализа содержит полную, объясненную и остаточные суммы квадратов, а также средние квадраты полученные из этих сумм и числа степеней свободы.
Можно показать, что для любой модели линейной регрессии справедливо соотношение:
$$ TSS = RSS + ESS, $$ 
где ESS (*Explained Sum of Squares*) - объясненная сумма квадратов:
$$ ESS= \sum{(\bar{y} - \hat{y_i})^2}$$
Это соотношение называется **формулой разложения дисперсии** (*Partition of Sum of Squares*).

Аналогичное соотношение справедливо и для числа степеней свободы при подсчете этих сумм:

$$ df_{TSS} = df_{RSS} + df_{ESS} $$

или:

$$ (N-1) = (k - 1) + (N - k) $$

Для простой линейной регрессии $k=2$, т.к. по выборке оценивается 2 коэффициента.


На основе этих соотношений могут быть вычислены средние квадраты (дисперсии):

- Полная дисперсия (Total Mean Square): 

$$ MST = TSS/df_{TSS} = TSS/(N-1)$$ 
- Объясненная дисперсия (Explained Mean Square): 
$$ MSE = ESS/df_{ESS} = ESS/(k-1)$$ 

- Необъясненная дисперсия (Residual Mean Square): 
$$ MSR = RSS/df_{RSS} = RSS/(N-k)$$


В R эти показатели можно вычислить с помощью функции `anova()`.

```{r Таблица дисперсионного анализа для линейной модели в R} 
anova(m_volume_costs)
```

Отношение объясненной и необъясненной дисперсий называется F-соотношением:

$$ F = \frac{MSE}{MSR} $$

Это соотношение является выборочной статистикой, которая применяется для проверки гипотезы об отсутствии в модели полезных предикторов. 
Для линейной регрессии:

$$ H_0 \colon \beta_1 = 0 $$ 

$$ H_1 \colon \beta_1 \ne 0 $$


Если верна нулевая гипотеза, то включение объясняющей переменной в модель не помогает снизить дисперсию выходной переменной. Поэтому $MSE$ и F-соотношение должны быть равны нулю. 

Для проверки гипотезы используется F-распределение Фишера. Как и в случае с другими критериями, наиболее важным компонентом таблицы является p-значение, которое позволяет судить о степени правдоподобия нулевой гипотезы - столбец  `Pr(>F)`. 

В случае с моделью на основе переменной `Delivery_volume` модель значима, т.к. p-value < .05. 

Как следствие, нулевая гипотеза отвергается и принимается альтернативная гипотеза о том, что в модели есть по крайней мере один полезный предиктор.

Для простой линейной регрессии этот тест не дает дополнительной информации по сравнению с проверкой значимости коэффициентов. Однако для моделей с несколькими факторами, F-критерий должен проверяться вначале, до проверки отдельных коэффициентов. Если по F-Критерию модель не значима, то и проверку значимости коэффициентов делать нельзя.

