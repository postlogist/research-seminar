
```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
options(width = 100) # ширина текстового вывода
options(digits = 3) # число знаков после запятой в выводе 
```



```{r Загрузка пакетов, message = F} 
library(readr) # считывание данных из текстовых файлов
library(tidyverse) # манипулирование данными 
library(ggplot2) # визуализация 
library(GGally) # построение матрицы диаграмм рассеяния 
library(ggfortify) # визуализация диагностических графиков
library(modelr) # вспомогательные функции для работы с моделями
library(broom) # преобразование результатов моделирования в табличный вид
library(readxl)
```



```{r Загрузка данных, message = F} 
random_data50 <- read_xlsx('test_dataset.xlsx', sheet='50')
random_data500 <- read_xlsx('test_dataset.xlsx', sheet='500')
random_data5000 <- read_xlsx('test_dataset.xlsx', sheet='5000')
volume_costs <- read_xlsx('test_dataset.xlsx', sheet='vol_costs')
glimpse(random_data50) # Структура данных 
summary(random_data50) # Описательная статистика + проверка пропущенных значений 
```

```{r}
m_rnd50 <- lm(y ~ x, data = random_data50) 
coef(m_rnd50) 
```
```{r}
m_rnd500 <- lm(y ~ x, data = random_data500) 
coef(m_rnd500) 
```
```{r}
m_rnd5000 <- lm(y ~ x, data = random_data5000) 
coef(m_rnd5000) 
```

```{r}
m_volume_costs <- lm(Costs ~ Volume, data = volume_costs) 
coef(m_volume_costs) 
```


## Исследование зависимостей в данных

Когда переменных немного, зависимости между каждым фактором и целевой переменной
можно искать с помощью обычных диаграмм рассеяния. Для быстрой оценки удобно
использовать **матрицу диаграмм рассеяния** (*scatterplot matrix, SPLOM*). В
базовой графике эту визуализацию можно получить с помощью функций `pairs()` или
`car::scatterplotMatrix()`.

Для визуализации с помощью `ggplot2` можно воспользоваться функцией
`GGally:ggpairs()`. В отличие от стандартной функции, `ggpairs()` позволяет
работать и с дискретными переменными.

Узнать о том, как настроить вид графика под свои нужды, можно в
[справке](http://ggobi.github.io/ggally/#ggallyggpairs).

```{r Матрица диаграмм рассеяния с помощью ggpairs}
ggpairs(m_volume_costs, columns = c("Costs", "Volume"),  
        lower = list(continuous = wrap("smooth_lm", color = 'blue'))) # добавили тренд и покрасили точки 
```
```{r Матрица диаграмм рассеяния с помощью ggpairs}
ggpairs(m_rnd500, columns = c("x", "y"),  
        lower = list(continuous = wrap("smooth_lm", color = 'blue'))) # добавили тренд и покрасили точки 
```


На главной диагонали содержатся плотности распределения соответствующих
переменных, над ней - коэффициенты корреляции Пирсона между парами переменных.
Под диагональю содержатся диаграммы рассеяния для каждой пары переменных.


Когда переменных много и надо показать только связь факторов и целевой
переменной, можно воспользоваться стандартными возможностями `ggplot()`, однако
придется изменить структуру данных. Данные надо перевести в "длинный" формат,
слив все столбцы в один. Для этого можно воспользоваться функцией
`tidyr::pivot_longer()` (см.
http://r4ds.had.co.nz/tidy-data.html#spreading-and-gathering)



## Корреляция: количественная оценка степени линейной связи

**Коэффициент корреляции Пирсона** $r$ (*The Pearson's product-moment
correlation*) позволяет количественно оценить степень выраженности (тесноту)
линейной связи между двумя непрерывными переменными:

$$ r = \frac{cov(x, y)}{S_x S_y} =
\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n S_x S_y} $$

Для вычисления коэффициента корреляции в R можно использовать встроенную функцию
`cor()`. Функция позволяет вычислять корреляцию между парой числовых переменных
(векторов), или для всех переменных в наборе данных сразу.


```{r Коэффициенты корреляции} 
# Для двух столбцов: 
cor(volume_costs$Volume, volume_costs$Costs)
#Для всех столбцов: 
options(digits = 3) # число знаков после запятой в выводе 
volume_costs %>% 
  cor() 
```

## Почему нужна визуализация?

Во встроенном наборе данных `anscombe` содержится 4 примера данных - т.н.
[квартет Энскомба](http://tinyurl.com/anscombe-quartet).

```{r Исходная структура anscombe} 
head(anscombe, 4) 
```

Для удобства, преобразуем данные в "длинный" формат: *номер примера, x, y*.
Использование функции everything() для выделения всех столбцов 
https://www.rdocumentation.org/packages/tidyselect/versions/1.0.0/topics/select_helpers
https://tidyr.tidyverse.org/reference/pivot_longer.html


```{r Преобразование структуры данных anscombe} 

anscombe_tall <- anscombe %>%
 pivot_longer(everything(),
   names_to = c(".value", "case"),
   names_pattern = "(.)(.)"
 )
head(anscombe_tall, 30)
anscombe_tall2 <- anscombe_tall
```

Рассчитаем коэффициенты корреляции:

```{r Коэффициенты корреляции для примера anscombe}
anscombe_tall %>% group_by(case) %>% summarize(r = cor(x, y))
```

Во всех 4 примерах коэффициенты корреляции равны с точностью до двух десятичных
знаков. Однако визуализация данных показывает совершенно различный характер
зависимостей:

```{r Визуализация данных anscombe} 
ggplot(data = anscombe_tall, mapping = aes(x, y)) + 
  geom_point() + 
  facet_wrap(~ case, ncol = 2, scales = 'free_x') + 
  geom_smooth(method = 'lm', se = F, color = 'red') +
  labs(title = "Примеры зависимостей с одинаковым r = 0.82")
```

**Вывод**: хотя коэффициент корреляции позволяет количественно оценить выраженность связи,
есть ограничения в его применении:

- выявляются только линейные зависимости, 
- показатель чувствителен к выбросам в данным.



На основе свойств выборочного распределения для $r$ можно проверить
статистическую гипотезу о равенстве нулю коэффициента корреляции для
совокупности:

$$ H_0: \rho_{xy} = 0 $$

$$ H_1: \rho_{xy} \ne 0 $$

В R для проверки значимости коэффициента корреляции используется функция
`cor.test()`:

```{r Проверка значимости коэффициента корреляции для случайных данных}
with(volume_costs, cor.test(Volume, Costs))
```
Для проверки гипотезы: $$H_0: \rho = 0$$ 

против альтернативной: $$H_1: \rho \ne 0$$

используется одновыборочный t-критерий.

Статистика критерия:

$$ t = \frac{r - 0}{SE(r)}$$

В сгенерированной выборке с двумя случайными независимыми переменными
вероятность получить такое же, или большее по модулю, значение коэффициента
корреляции оказалась равна 0.08%. Таким образом, есть основания отвергнуть нулевую гипотезу.
Рассчитанное по выборке значение $r$ статистически  значимо. То есть, оно
говорит о наличии связи между $x$ и $y$ в генеральной совокупности.


```{r Проверка значимости коэффициента корреляции для случайных данных}
with(random_data50, cor.test(x, y))
```

```{r Проверка значимости коэффициента корреляции для случайных данных}
with(random_data5000, cor.test(x, y))
```

Для проверки гипотезы: $$H_0: \rho = 0$$ 

против альтернативной: $$H_1: \rho \ne 0$$

используется одновыборочный t-критерий.

Статистика критерия:

$$ t = \frac{r - 0}{SE(r)}$$

```{r}

anscombe_tall_case2 <- anscombe_tall2 %>%
  filter (case == '2')
anscombe_tall_case1
```
```{r Проверка значимости коэффициента корреляции для случайных данных}
with(anscombe_tall_case2, cor.test(x, y))
```

